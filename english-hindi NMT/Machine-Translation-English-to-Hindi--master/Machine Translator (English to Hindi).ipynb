{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Bad key \"text.kerning_factor\" on line 4 in\n",
      "C:\\Users\\Sriram Saran Cheruvu\\.conda\\envs\\tensorflow\\lib\\site-packages\\matplotlib\\mpl-data\\stylelib\\_classic_test_patch.mplstyle.\n",
      "You probably need to get an updated matplotlibrc file from\n",
      "https://github.com/matplotlib/matplotlib/blob/v3.1.3/matplotlibrc.template\n",
      "or from the matplotlib source distribution\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "C:\\Users\\Sriram Saran Cheruvu\\.conda\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Users\\Sriram Saran Cheruvu\\.conda\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Users\\Sriram Saran Cheruvu\\.conda\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Users\\Sriram Saran Cheruvu\\.conda\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Users\\Sriram Saran Cheruvu\\.conda\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Users\\Sriram Saran Cheruvu\\.conda\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "C:\\Users\\Sriram Saran Cheruvu\\.conda\\envs\\tensorflow\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Users\\Sriram Saran Cheruvu\\.conda\\envs\\tensorflow\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Users\\Sriram Saran Cheruvu\\.conda\\envs\\tensorflow\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Users\\Sriram Saran Cheruvu\\.conda\\envs\\tensorflow\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Users\\Sriram Saran Cheruvu\\.conda\\envs\\tensorflow\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Users\\Sriram Saran Cheruvu\\.conda\\envs\\tensorflow\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Model\n",
    "from keras.layers import Input, LSTM, Dense\n",
    "import numpy as np\n",
    "import io\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jump.\tउछलो.\n",
      "['Help!', 'बचाओ!']\n"
     ]
    }
   ],
   "source": [
    "# Assign the data path.\n",
    "data_path = \"hin.txt\"\n",
    "\n",
    "# Read in the data.\n",
    "lines = io.open(data_path, encoding = \"utf-8\").read().split(\"\\n\")\n",
    "lines  = lines[:-1]\n",
    "print(lines[1])\n",
    "# Split the data into input and target sequences.\n",
    "lines = [line.split(\"\\t\") for line in lines]\n",
    "print(lines[0])\n",
    "# We define the starting signal to be \"\\t\" and the\n",
    "# ending signal to be \"\\n\". These signals tell the\n",
    "# model that when it sees \"\\t\" it should start\n",
    "# producing its translation and produce \"\\n\" when\n",
    "# it wants to end its translation. Let us add\n",
    "# \"\\t\" to the start and \"\\n\" to the end \n",
    "# of all input and output sentences.\n",
    "lines = [(\"\\t\" + line[0] + \"\\n\", \"\\t\" + line[1] + \"\\n\") for\n",
    "            line in lines]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tकूदो.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print (lines[2][1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute Sentence Lengths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the input and output lengths.\n",
    "input_lengths = np.array([len(line[0]) for line in lines])\n",
    "output_lengths = np.array([len(line[1]) for line in lines])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2869\n"
     ]
    }
   ],
   "source": [
    "print (len(input_lengths))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[75, 80, 0, 120]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(input_lengths)\n",
    "plt.axis([75,80, 0 , 120])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[85, 89, 0, 20]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(output_lengths)\n",
    "plt.axis([85,89,0,20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "english = 78\n",
    "hindi = 87"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "line1 = []\n",
    "for i in range(len(input_lengths)):\n",
    "    if(input_lengths[i]<75 and output_lengths[i]<85):\n",
    "        line1 = line1 + [lines[i]]\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2856"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " len(line1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Input Length"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plotted the histogram of the length of the input sentences and choose the length that makes the most sense. \n",
    "\n",
    "The reason we don't want sentences that are too long is because the computation becomes trickier for longer sentences and the performance also degrades. However we also want as many sentences in our dataset as possible.\n",
    "\n",
    "Thus it is important to choose the right length and discard sentences longer than this."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Output Length"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Repeat the same for the lengths of the output sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64  # Batch size for training.\n",
    "epochs = 100  # Number of epochs to train for.\n",
    "latent_dim = 256  # Latent dimensionality of the encoding space.\n",
    "num_samples = 2869  # Number of samples to train on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_texts = [(line[0]) for line in line1]\n",
    "target_texts = [(line[1]) for line in line1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_characters = set()\n",
    "target_characters = set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "for input_text in input_texts:\n",
    "    for char in input_text:\n",
    "        if char not in input_characters:\n",
    "            input_characters.add(char)\n",
    "\n",
    "for target_text in target_texts:\n",
    "    for char in target_text:\n",
    "        if char not in target_characters:\n",
    "            target_characters.add(char)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "72\n",
      "92\n"
     ]
    }
   ],
   "source": [
    "print (len(input_characters))\n",
    "print (len(target_characters))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_characters = sorted(list(input_characters))\n",
    "target_characters = sorted(list(target_characters))\n",
    "num_encoder_tokens = len(input_characters)\n",
    "num_decoder_tokens = len(target_characters)\n",
    "max_encoder_seq_length = max([len(txt) for txt in input_texts])\n",
    "max_decoder_seq_length = max([len(txt) for txt in target_texts])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of samples: 2856\n",
      "Number of unique input tokens: 72\n",
      "Number of unique output tokens: 92\n",
      "Max sequence length for inputs: 74\n",
      "Max sequence length for outputs: 82\n"
     ]
    }
   ],
   "source": [
    "print('Number of samples:', len(input_texts))\n",
    "print('Number of unique input tokens:', num_encoder_tokens)\n",
    "print('Number of unique output tokens:', num_decoder_tokens)\n",
    "print('Max sequence length for inputs:', max_encoder_seq_length)\n",
    "print('Max sequence length for outputs:', max_decoder_seq_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_token_index = dict(\n",
    "    [(char, i) for i, char in enumerate(input_characters)])\n",
    "target_token_index = dict(\n",
    "    [(char, i) for i, char in enumerate(target_characters)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_input_data = np.zeros(\n",
    "    (len(input_texts), max_encoder_seq_length, num_encoder_tokens),\n",
    "    dtype='float32')\n",
    "decoder_input_data = np.zeros(\n",
    "    (len(input_texts), max_decoder_seq_length, num_decoder_tokens),\n",
    "    dtype='float32')\n",
    "decoder_target_data = np.zeros(\n",
    "    (len(input_texts), max_decoder_seq_length, num_decoder_tokens),\n",
    "    dtype='float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, (input_text, target_text) in enumerate(zip(input_texts, target_texts)):\n",
    "    for t, char in enumerate(input_text):\n",
    "        encoder_input_data[i, t, input_token_index[char]] = 1.\n",
    "    for t, char in enumerate(target_text):\n",
    "        decoder_input_data[i, t, target_token_index[char]] = 1.\n",
    "        if t > 0:\n",
    "            \n",
    "            decoder_target_data[i, t - 1, target_token_index[char]] = 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "encoder_inputs = Input(shape=(None, num_encoder_tokens))\n",
    "encoder = LSTM(latent_dim, return_state=True)\n",
    "encoder_outputs, state_h, state_c = encoder(encoder_inputs)\n",
    "\n",
    "encoder_states = [state_h, state_c]\n",
    "\n",
    "decoder_inputs = Input(shape=(None, num_decoder_tokens))\n",
    "\n",
    "decoder_lstm = LSTM(latent_dim, return_sequences=True, return_state=True)\n",
    "decoder_outputs, _, _ = decoder_lstm(decoder_inputs,\n",
    "                                     initial_state=encoder_states)\n",
    "decoder_dense = Dense(num_decoder_tokens, activation='softmax')\n",
    "decoder_outputs = decoder_dense(decoder_outputs)\n",
    "\n",
    "model = Model([encoder_inputs, decoder_inputs], decoder_outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='rmsprop', loss='categorical_crossentropy')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Sriram Saran Cheruvu\\.conda\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\ops\\math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "WARNING:tensorflow:From C:\\Users\\Sriram Saran Cheruvu\\.conda\\envs\\tensorflow\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "Train on 2284 samples, validate on 572 samples\n",
      "Epoch 1/100\n",
      "2284/2284 [==============================] - 24s 10ms/step - loss: 1.2298 - val_loss: 1.8767\n",
      "Epoch 2/100\n",
      "2284/2284 [==============================] - 22s 10ms/step - loss: 1.1327 - val_loss: 1.8302\n",
      "Epoch 3/100\n",
      "2284/2284 [==============================] - 21s 9ms/step - loss: 1.0742 - val_loss: 1.7571\n",
      "Epoch 4/100\n",
      "2284/2284 [==============================] - 21s 9ms/step - loss: 0.9791 - val_loss: 1.6378\n",
      "Epoch 5/100\n",
      "2284/2284 [==============================] - 21s 9ms/step - loss: 0.9517 - val_loss: 1.5416\n",
      "Epoch 6/100\n",
      "2284/2284 [==============================] - 21s 9ms/step - loss: 0.8748 - val_loss: 1.4701\n",
      "Epoch 7/100\n",
      "2284/2284 [==============================] - 21s 9ms/step - loss: 0.8174 - val_loss: 1.3947\n",
      "Epoch 8/100\n",
      "2284/2284 [==============================] - 21s 9ms/step - loss: 0.7837 - val_loss: 1.3372\n",
      "Epoch 9/100\n",
      "2284/2284 [==============================] - 21s 9ms/step - loss: 0.7566 - val_loss: 1.3079\n",
      "Epoch 10/100\n",
      "2284/2284 [==============================] - 21s 9ms/step - loss: 0.7432 - val_loss: 1.2945\n",
      "Epoch 11/100\n",
      "2284/2284 [==============================] - 22s 9ms/step - loss: 0.7195 - val_loss: 1.2491\n",
      "Epoch 12/100\n",
      "2284/2284 [==============================] - 22s 10ms/step - loss: 0.7045 - val_loss: 1.2267\n",
      "Epoch 13/100\n",
      "2284/2284 [==============================] - 21s 9ms/step - loss: 0.6924 - val_loss: 1.2157\n",
      "Epoch 14/100\n",
      "2284/2284 [==============================] - 21s 9ms/step - loss: 0.6810 - val_loss: 1.2074\n",
      "Epoch 15/100\n",
      "2284/2284 [==============================] - 21s 9ms/step - loss: 0.6697 - val_loss: 1.2010\n",
      "Epoch 16/100\n",
      "2284/2284 [==============================] - 23s 10ms/step - loss: 0.6596 - val_loss: 1.1878\n",
      "Epoch 17/100\n",
      "2284/2284 [==============================] - 21s 9ms/step - loss: 0.6504 - val_loss: 1.1738\n",
      "Epoch 18/100\n",
      "2284/2284 [==============================] - 21s 9ms/step - loss: 0.6481 - val_loss: 1.1707\n",
      "Epoch 19/100\n",
      "2284/2284 [==============================] - 21s 9ms/step - loss: 0.6327 - val_loss: 1.1925\n",
      "Epoch 20/100\n",
      "2284/2284 [==============================] - 25s 11ms/step - loss: 0.6251 - val_loss: 1.1542\n",
      "Epoch 21/100\n",
      "2284/2284 [==============================] - 25s 11ms/step - loss: 0.6164 - val_loss: 1.1446\n",
      "Epoch 22/100\n",
      "2284/2284 [==============================] - 21s 9ms/step - loss: 0.6094 - val_loss: 1.1518\n",
      "Epoch 23/100\n",
      "2284/2284 [==============================] - 21s 9ms/step - loss: 0.6045 - val_loss: 1.1254\n",
      "Epoch 24/100\n",
      "2284/2284 [==============================] - 21s 9ms/step - loss: 0.5944 - val_loss: 1.1255\n",
      "Epoch 25/100\n",
      "2284/2284 [==============================] - 21s 9ms/step - loss: 0.5875 - val_loss: 1.1375\n",
      "Epoch 26/100\n",
      "2284/2284 [==============================] - 21s 9ms/step - loss: 0.5805 - val_loss: 1.1092\n",
      "Epoch 27/100\n",
      "2284/2284 [==============================] - 21s 9ms/step - loss: 0.5728 - val_loss: 1.1203\n",
      "Epoch 28/100\n",
      "2284/2284 [==============================] - 22s 10ms/step - loss: 0.5663 - val_loss: 1.1071\n",
      "Epoch 29/100\n",
      "2284/2284 [==============================] - 24s 10ms/step - loss: 0.5590 - val_loss: 1.1039\n",
      "Epoch 30/100\n",
      "2284/2284 [==============================] - 23s 10ms/step - loss: 0.5527 - val_loss: 1.0864\n",
      "Epoch 31/100\n",
      "2284/2284 [==============================] - 22s 9ms/step - loss: 0.5463 - val_loss: 1.0923\n",
      "Epoch 32/100\n",
      "2284/2284 [==============================] - 26s 12ms/step - loss: 0.5386 - val_loss: 1.0998\n",
      "Epoch 33/100\n",
      "2284/2284 [==============================] - 27s 12ms/step - loss: 0.5321 - val_loss: 1.2136\n",
      "Epoch 34/100\n",
      "2284/2284 [==============================] - 28s 12ms/step - loss: 0.5387 - val_loss: 1.1007\n",
      "Epoch 35/100\n",
      "2284/2284 [==============================] - 26s 11ms/step - loss: 0.5233 - val_loss: 1.1045\n",
      "Epoch 36/100\n",
      "2284/2284 [==============================] - 27s 12ms/step - loss: 0.5141 - val_loss: 1.0930\n",
      "Epoch 37/100\n",
      "2284/2284 [==============================] - 27s 12ms/step - loss: 0.5068 - val_loss: 1.0918\n",
      "Epoch 38/100\n",
      "2284/2284 [==============================] - 22s 10ms/step - loss: 0.5032 - val_loss: 1.0875\n",
      "Epoch 39/100\n",
      "2284/2284 [==============================] - 22s 10ms/step - loss: 0.4947 - val_loss: 1.0844\n",
      "Epoch 40/100\n",
      "2284/2284 [==============================] - 22s 10ms/step - loss: 0.4859 - val_loss: 1.0919\n",
      "Epoch 41/100\n",
      "2284/2284 [==============================] - 22s 10ms/step - loss: 0.4773 - val_loss: 1.0998\n",
      "Epoch 42/100\n",
      "2284/2284 [==============================] - 22s 10ms/step - loss: 0.4704 - val_loss: 1.0988\n",
      "Epoch 43/100\n",
      "2284/2284 [==============================] - 22s 10ms/step - loss: 0.4633 - val_loss: 1.1010\n",
      "Epoch 44/100\n",
      "2284/2284 [==============================] - 23s 10ms/step - loss: 0.4558 - val_loss: 1.1055\n",
      "Epoch 45/100\n",
      "2284/2284 [==============================] - 24s 10ms/step - loss: 0.4494 - val_loss: 1.1149\n",
      "Epoch 46/100\n",
      "2284/2284 [==============================] - 22s 10ms/step - loss: 0.4428 - val_loss: 1.1227\n",
      "Epoch 47/100\n",
      "2284/2284 [==============================] - 22s 10ms/step - loss: 0.4363 - val_loss: 1.1330\n",
      "Epoch 48/100\n",
      "2284/2284 [==============================] - 22s 10ms/step - loss: 0.4291 - val_loss: 1.1141\n",
      "Epoch 49/100\n",
      "2284/2284 [==============================] - 22s 10ms/step - loss: 0.4215 - val_loss: 1.1449\n",
      "Epoch 50/100\n",
      "2284/2284 [==============================] - 23s 10ms/step - loss: 0.4162 - val_loss: 1.1334\n",
      "Epoch 51/100\n",
      "2284/2284 [==============================] - 23s 10ms/step - loss: 0.4085 - val_loss: 1.1288\n",
      "Epoch 52/100\n",
      "2284/2284 [==============================] - 22s 10ms/step - loss: 0.4005 - val_loss: 1.1415\n",
      "Epoch 53/100\n",
      "2284/2284 [==============================] - 24s 11ms/step - loss: 0.3946 - val_loss: 1.1426\n",
      "Epoch 54/100\n",
      "2284/2284 [==============================] - 27s 12ms/step - loss: 0.3887 - val_loss: 1.1722\n",
      "Epoch 55/100\n",
      "2284/2284 [==============================] - 22s 10ms/step - loss: 0.3811 - val_loss: 1.1644\n",
      "Epoch 56/100\n",
      "2284/2284 [==============================] - 22s 10ms/step - loss: 0.3740 - val_loss: 1.1789\n",
      "Epoch 57/100\n",
      "2284/2284 [==============================] - 22s 10ms/step - loss: 0.3698 - val_loss: 1.1721\n",
      "Epoch 58/100\n",
      "2284/2284 [==============================] - 23s 10ms/step - loss: 0.3652 - val_loss: 1.1876\n",
      "Epoch 59/100\n",
      "2284/2284 [==============================] - 22s 10ms/step - loss: 0.3560 - val_loss: 1.2120\n",
      "Epoch 60/100\n",
      "2284/2284 [==============================] - 23s 10ms/step - loss: 0.3541 - val_loss: 1.2210\n",
      "Epoch 61/100\n",
      "2284/2284 [==============================] - 22s 10ms/step - loss: 0.3473 - val_loss: 1.2238\n",
      "Epoch 62/100\n",
      "2284/2284 [==============================] - 22s 10ms/step - loss: 0.3405 - val_loss: 1.2171\n",
      "Epoch 63/100\n",
      "2284/2284 [==============================] - 22s 10ms/step - loss: 0.3333 - val_loss: 1.2555\n",
      "Epoch 64/100\n",
      "2284/2284 [==============================] - 22s 10ms/step - loss: 0.3277 - val_loss: 1.2526\n",
      "Epoch 65/100\n",
      "2284/2284 [==============================] - 24s 11ms/step - loss: 0.3218 - val_loss: 1.2554\n",
      "Epoch 66/100\n",
      "2284/2284 [==============================] - 23s 10ms/step - loss: 0.3158 - val_loss: 1.2733\n",
      "Epoch 67/100\n",
      "2284/2284 [==============================] - 23s 10ms/step - loss: 0.3109 - val_loss: 1.2797\n",
      "Epoch 68/100\n",
      "2284/2284 [==============================] - 23s 10ms/step - loss: 0.3052 - val_loss: 1.2789\n",
      "Epoch 69/100\n",
      "2284/2284 [==============================] - 22s 10ms/step - loss: 0.3009 - val_loss: 1.2929\n",
      "Epoch 70/100\n",
      "2284/2284 [==============================] - 22s 10ms/step - loss: 0.2946 - val_loss: 1.3154\n",
      "Epoch 71/100\n",
      "2284/2284 [==============================] - 23s 10ms/step - loss: 0.2890 - val_loss: 1.3145\n",
      "Epoch 72/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2284/2284 [==============================] - 23s 10ms/step - loss: 0.2841 - val_loss: 1.3366\n",
      "Epoch 73/100\n",
      "2284/2284 [==============================] - 24s 11ms/step - loss: 0.2803 - val_loss: 1.3512\n",
      "Epoch 74/100\n",
      "2284/2284 [==============================] - 23s 10ms/step - loss: 0.2753 - val_loss: 1.3428\n",
      "Epoch 75/100\n",
      "2284/2284 [==============================] - 22s 10ms/step - loss: 0.2691 - val_loss: 1.3816\n",
      "Epoch 76/100\n",
      "2284/2284 [==============================] - 22s 10ms/step - loss: 0.2675 - val_loss: 1.3624\n",
      "Epoch 77/100\n",
      "2284/2284 [==============================] - 22s 10ms/step - loss: 0.2603 - val_loss: 1.3912\n",
      "Epoch 78/100\n",
      "2284/2284 [==============================] - 22s 10ms/step - loss: 0.2559 - val_loss: 1.4189\n",
      "Epoch 79/100\n",
      "2284/2284 [==============================] - 23s 10ms/step - loss: 0.2526 - val_loss: 1.4137\n",
      "Epoch 80/100\n",
      "2284/2284 [==============================] - 25s 11ms/step - loss: 0.2475 - val_loss: 1.4207\n",
      "Epoch 81/100\n",
      "2284/2284 [==============================] - 23s 10ms/step - loss: 0.2439 - val_loss: 1.4631\n",
      "Epoch 82/100\n",
      "2284/2284 [==============================] - 24s 11ms/step - loss: 0.2409 - val_loss: 1.4559\n",
      "Epoch 83/100\n",
      "2284/2284 [==============================] - 23s 10ms/step - loss: 0.2365 - val_loss: 1.4458\n",
      "Epoch 84/100\n",
      "2284/2284 [==============================] - 23s 10ms/step - loss: 0.2323 - val_loss: 1.4908\n",
      "Epoch 85/100\n",
      "2284/2284 [==============================] - 23s 10ms/step - loss: 0.2289 - val_loss: 1.5009\n",
      "Epoch 86/100\n",
      "2284/2284 [==============================] - 22s 10ms/step - loss: 0.2244 - val_loss: 1.4814\n",
      "Epoch 87/100\n",
      "2284/2284 [==============================] - 22s 10ms/step - loss: 0.2218 - val_loss: 1.5050\n",
      "Epoch 88/100\n",
      "2284/2284 [==============================] - 22s 10ms/step - loss: 0.2184 - val_loss: 1.5270\n",
      "Epoch 89/100\n",
      "2284/2284 [==============================] - 22s 10ms/step - loss: 0.2141 - val_loss: 1.5202\n",
      "Epoch 90/100\n",
      "2284/2284 [==============================] - 22s 10ms/step - loss: 0.2104 - val_loss: 1.5530\n",
      "Epoch 91/100\n",
      "2284/2284 [==============================] - 22s 10ms/step - loss: 0.2080 - val_loss: 1.5549\n",
      "Epoch 92/100\n",
      "2284/2284 [==============================] - 22s 10ms/step - loss: 0.2049 - val_loss: 1.5498\n",
      "Epoch 93/100\n",
      "2284/2284 [==============================] - 22s 10ms/step - loss: 0.2004 - val_loss: 1.5565\n",
      "Epoch 94/100\n",
      "2284/2284 [==============================] - 22s 10ms/step - loss: 0.1993 - val_loss: 1.5804\n",
      "Epoch 95/100\n",
      "2284/2284 [==============================] - 22s 10ms/step - loss: 0.1955 - val_loss: 1.5873\n",
      "Epoch 96/100\n",
      "2284/2284 [==============================] - 22s 10ms/step - loss: 0.1926 - val_loss: 1.5890\n",
      "Epoch 97/100\n",
      "2284/2284 [==============================] - 22s 10ms/step - loss: 0.1902 - val_loss: 1.6066\n",
      "Epoch 98/100\n",
      "2284/2284 [==============================] - 26s 11ms/step - loss: 0.1873 - val_loss: 1.6415\n",
      "Epoch 99/100\n",
      "2284/2284 [==============================] - 26s 11ms/step - loss: 0.1847 - val_loss: 1.6312\n",
      "Epoch 100/100\n",
      "2284/2284 [==============================] - 23s 10ms/step - loss: 0.1817 - val_loss: 1.6382\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x19d916abcc0>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit([encoder_input_data, decoder_input_data], decoder_target_data,batch_size=batch_size,epochs=epochs,validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('s2s.h5')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_model = Model(encoder_inputs, encoder_states)\n",
    "\n",
    "decoder_state_input_h = Input(shape=(latent_dim,))\n",
    "decoder_state_input_c = Input(shape=(latent_dim,))\n",
    "decoder_states_inputs = [decoder_state_input_h, decoder_state_input_c]\n",
    "decoder_outputs, state_h, state_c = decoder_lstm(\n",
    "    decoder_inputs, initial_state=decoder_states_inputs)\n",
    "decoder_states = [state_h, state_c]\n",
    "decoder_outputs = decoder_dense(decoder_outputs)\n",
    "decoder_model = Model(\n",
    "    [decoder_inputs] + decoder_states_inputs,\n",
    "    [decoder_outputs] + decoder_states)\n",
    "\n",
    "reverse_input_char_index = dict(\n",
    "    (i, char) for char, i in input_token_index.items())\n",
    "reverse_target_char_index = dict(\n",
    "    (i, char) for char, i in target_token_index.items())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode_sequence(input_seq):\n",
    "    states_value = encoder_model.predict(input_seq)\n",
    "\n",
    "    target_seq = np.zeros((1, 1, num_decoder_tokens))\n",
    "    target_seq[0, 0, target_token_index['\\t']] = 1.\n",
    "\n",
    "    stop_condition = False\n",
    "    decoded_sentence = ''\n",
    "    while not stop_condition:\n",
    "        output_tokens, h, c = decoder_model.predict(\n",
    "            [target_seq] + states_value)\n",
    "\n",
    "        sampled_token_index = np.argmax(output_tokens[0, -1, :])\n",
    "        sampled_char = reverse_target_char_index[sampled_token_index]\n",
    "        decoded_sentence += sampled_char\n",
    "\n",
    "        if (sampled_char == '\\n' or\n",
    "           len(decoded_sentence) > max_decoder_seq_length):\n",
    "            stop_condition = True\n",
    "\n",
    "        target_seq = np.zeros((1, 1, num_decoder_tokens))\n",
    "        target_seq[0, 0, sampled_token_index] = 1.\n",
    "\n",
    "        states_value = [h, c]\n",
    "\n",
    "    return decoded_sentence\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-\n",
      "\tHelp!\n",
      "\n",
      "वह अपने कुत्ते को खादरा भर सकता।\n",
      "\n",
      "-\n",
      "\tJump.\n",
      "\n",
      "हम सब तुम्हारी सेहत के लिए बहुत छोटा है।\n",
      "\n",
      "-\n",
      "\tJump.\n",
      "\n",
      "हम सब तुम्हारी सेहत के लिए बहुत छोटा है।\n",
      "\n",
      "-\n",
      "\tJump.\n",
      "\n",
      "हम सब तुम्हारी सेहत के लिए बहुत छोटा है।\n",
      "\n",
      "-\n",
      "\tHello!\n",
      "\n",
      "वह अफ़वाह सच्चिय सकता है।\n",
      "\n",
      "-\n",
      "\tHello!\n",
      "\n",
      "वह अफ़वाह सच्चिय सकता है।\n",
      "\n",
      "-\n",
      "\tCheers!\n",
      "\n",
      "हमारे पास कितनी कट्रियाँगें मुलाई है।\n",
      "\n",
      "-\n",
      "\tCheers!\n",
      "\n",
      "हमारे पास कितनी कट्रियाँगें मुलाई है।\n",
      "\n",
      "-\n",
      "\tGot it?\n",
      "\n",
      "मुझे अपने आपसी बास नहीं जातते हैं।\n",
      "\n",
      "-\n",
      "\tI'm OK.\n",
      "\n",
      "मैं अपनी काई बजास सुन किता हूँ।\n",
      "\n",
      "-\n",
      "\tAwesome!\n",
      "\n",
      "हम सब तुम्हारी सेहत के लिए बहुत छोटा है।\n",
      "\n",
      "-\n",
      "\tCome in.\n",
      "\n",
      "मुझे अपने आपसी बास नहीं जातते हैं।\n",
      "\n",
      "-\n",
      "\tGet out!\n",
      "\n",
      "मुझे अपने आपसी बादी नाड़ के निक्यों के पाला नहीं है।\n",
      "\n",
      "-\n",
      "\tGo away!\n",
      "\n",
      "हम सब तुम्हारी सेहत के लिए बहुत छोटा है।\n",
      "\n",
      "-\n",
      "\tGoodbye!\n",
      "\n",
      "मुझे अपने आपसी बास नहीं जातते हैं।\n",
      "\n",
      "-\n",
      "\tPerfect!\n",
      "\n",
      "मुझे अपने आपसी बादी नाड़ के निक्यों के पाला नहीं है।\n",
      "\n",
      "-\n",
      "\tPerfect!\n",
      "\n",
      "मुझे अपने आपसी बादी नाड़ के निक्यों के पाला नहीं है।\n",
      "\n",
      "-\n",
      "\tWelcome.\n",
      "\n",
      "हमारे साथ आओ।\n",
      "\n",
      "-\n",
      "\tWelcome.\n",
      "\n",
      "हमारे साथ आओ।\n",
      "\n",
      "-\n",
      "\tHave fun.\n",
      "\n",
      "हम सब तुम्हारी सेहत के लिए बहुत छोटा है।\n",
      "\n",
      "-\n",
      "\tHave fun.\n",
      "\n",
      "हम सब तुम्हारी सेहत के लिए बहुत छोटा है।\n",
      "\n",
      "-\n",
      "\tHave fun.\n",
      "\n",
      "हम सब तुम्हारी सेहत के लिए बहुत छोटा है।\n",
      "\n",
      "-\n",
      "\tI forgot.\n",
      "\n",
      "मैं अपनी काई बजास सुन किता हूँ।\n",
      "\n",
      "-\n",
      "\tI forgot.\n",
      "\n",
      "मैं अपनी काई बजास सुन किता हूँ।\n",
      "\n",
      "-\n",
      "\tI'll pay.\n",
      "\n",
      "मैं अपनी काई बजास सुन किता हूँ।\n",
      "\n",
      "-\n",
      "\tI'm fine.\n",
      "\n",
      "मैं अपनी काई बजास सुन किता हूँ।\n",
      "\n",
      "-\n",
      "\tI'm full.\n",
      "\n",
      "मैं अपनी काई बजास सुन किता हूँ।\n",
      "\n",
      "-\n",
      "\tLet's go!\n",
      "\n",
      "यह मेरा पत्हैंका खाशवा है।\n",
      "\n",
      "-\n",
      "\tAnswer me.\n",
      "\n",
      "हम सब तुम्हारी सेहत के लिए बहुत छोटा है।\n",
      "\n",
      "-\n",
      "\tBirds fly.\n",
      "\n",
      "यह मेरी बहन की तम्मन्य है कह सुमस्ता है।\n",
      "\n",
      "-\n",
      "\tExcuse me.\n",
      "\n",
      "मेरे पापा बहुत अच्छे हैं।\n",
      "\n",
      "-\n",
      "\tFantastic!\n",
      "\n",
      "मुझे अपने आपसी बास नहीं जातते हैं।\n",
      "\n",
      "-\n",
      "\tI fear so.\n",
      "\n",
      "मैं अपनी काई बजास सुन किता हूँ।\n",
      "\n",
      "-\n",
      "\tI laughed.\n",
      "\n",
      "मैं अपनी काई बजास सुन किता हूँ।\n",
      "\n",
      "-\n",
      "\tI'm bored.\n",
      "\n",
      "मैं अपनी काई बजास सुन किता हूँ।\n",
      "\n",
      "-\n",
      "\tI'm broke.\n",
      "\n",
      "मैं अपनी काई बजास सुन किता हूँ।\n",
      "\n",
      "-\n",
      "\tI'm tired.\n",
      "\n",
      "मैं अपनी काई बजास सुन किता हूँ।\n",
      "\n",
      "-\n",
      "\tIt's cold.\n",
      "\n",
      "मुझे अपने आपसी बदद कींते हैं।\n",
      "\n",
      "-\n",
      "\tWho knows?\n",
      "\n",
      "तुम कितने सेल से स्तेत के लिए आते हो?\n",
      "\n",
      "-\n",
      "\tWho knows?\n",
      "\n",
      "तुम कितने सेल से स्तेत के लिए आते हो?\n",
      "\n",
      "-\n",
      "\tWho knows?\n",
      "\n",
      "तुम कितने सेल से स्तेत के लिए आते हो?\n",
      "\n",
      "-\n",
      "\tWho knows?\n",
      "\n",
      "तुम कितने सेल से स्तेत के लिए आते हो?\n",
      "\n",
      "-\n",
      "\tWonderful!\n",
      "\n",
      "तुम कितने बजे घर जाते हो?\n",
      "\n",
      "-\n",
      "\tBirds sing.\n",
      "\n",
      "यह मेरा हैसा नहाँ है।\n",
      "\n",
      "-\n",
      "\tCome on in.\n",
      "\n",
      "मुझे अपने आपसी बास नहीं जातेंगे।\n",
      "\n",
      "-\n",
      "\tDefinitely!\n",
      "\n",
      "मुझे अपने आपसी बाद फ़ुन सकते हैं।\n",
      "\n",
      "-\n",
      "\tDon't move.\n",
      "\n",
      "मुझे अपने आपसी बास नहीं जातते हैं।\n",
      "\n",
      "-\n",
      "\tFire burns.\n",
      "\n",
      "मुझे अपने आपसी बास नहीं जातते हैं।\n",
      "\n",
      "-\n",
      "\tFollow him.\n",
      "\n",
      "मुझे अपने आपसी बास नहीं जातते हैं।\n",
      "\n",
      "-\n",
      "\tI am tired.\n",
      "\n",
      "मैं अपनी काई बजास सुन किता हूँ।\n",
      "\n",
      "-\n",
      "\tI can swim.\n",
      "\n",
      "मैं अपनी काई बजास सुन किता हूँ।\n",
      "\n",
      "-\n",
      "\tI can swim.\n",
      "\n",
      "मैं अपनी काई बजास सुन किता हूँ।\n",
      "\n",
      "-\n",
      "\tI love you.\n",
      "\n",
      "मैं अपनी काई बजास सुन किता हूँ।\n",
      "\n",
      "-\n",
      "\tI love you.\n",
      "\n",
      "मैं अपनी काई बजास सुन किता हूँ।\n",
      "\n",
      "-\n",
      "\tI love you.\n",
      "\n",
      "मैं अपनी काई बजास सुन किता हूँ।\n",
      "\n",
      "-\n",
      "\tI love you.\n",
      "\n",
      "मैं अपनी काई बजास सुन किता हूँ।\n",
      "\n",
      "-\n",
      "\tI love you.\n",
      "\n",
      "मैं अपनी काई बजास सुन किता हूँ।\n",
      "\n",
      "-\n",
      "\tI will try.\n",
      "\n",
      "मैं अपनी काई बजास सुन किता हूँ।\n",
      "\n",
      "-\n",
      "\tI'm coming.\n",
      "\n",
      "मैं अपनी काई बजास सुन किता हूँ।\n",
      "\n",
      "-\n",
      "\tI'm hungry!\n",
      "\n",
      "मैं अपनी काई बजास सुन किता हूँ।\n",
      "\n",
      "-\n",
      "\tI'm hungry!\n",
      "\n",
      "मैं अपनी काई बजास सुन किता हूँ।\n",
      "\n",
      "-\n",
      "\tLet him in.\n",
      "\n",
      "वे आज मेरे लिए बहुत बड़ा है।\n",
      "\n",
      "-\n",
      "\tLet him in.\n",
      "\n",
      "वे आज मेरे लिए बहुत बड़ा है।\n",
      "\n",
      "-\n",
      "\tLet me out!\n",
      "\n",
      "मुझे अपने आपसे पैसे सेल सचते हैं।\n",
      "\n",
      "-\n",
      "\tOnce again.\n",
      "\n",
      "हम सब तुम्हारी सेहत के लिए बहुत छोटा है।\n",
      "\n",
      "-\n",
      "\tPlease sit.\n",
      "\n",
      "मुझे अपने आपसी बदद कींते हैं।\n",
      "\n",
      "-\n",
      "\tWhat's new?\n",
      "\n",
      "तुम कितने सेल से स्तेत के लिए आते हो?\n",
      "\n",
      "-\n",
      "\tWhat's new?\n",
      "\n",
      "तुम कितने सेल से स्तेत के लिए आते हो?\n",
      "\n",
      "-\n",
      "\tWho's that?\n",
      "\n",
      "तुम कितने सेल से स्तेत के लिए आते हो क्या?\n",
      "\n",
      "-\n",
      "\tDon't shout.\n",
      "\n",
      "मुझे अपने आपसी बास नहीं जातते हैं।\n",
      "\n",
      "-\n",
      "\tDon't shout.\n",
      "\n",
      "मुझे अपने आपसी बास नहीं जातते हैं।\n",
      "\n",
      "-\n",
      "\tHe stood up.\n",
      "\n",
      "वह अपने कुत्ते को खादाना भी नही है।\n",
      "\n",
      "-\n",
      "\tHe's strong.\n",
      "\n",
      "वह अपने कुत्ते को खादरा भर मकाने कर लिया था।\n",
      "\n",
      "-\n",
      "\tHow are you?\n",
      "\n",
      "तुम कितने सेल से स्तेत के लिए बहती है?\n",
      "\n",
      "-\n",
      "\tHow are you?\n",
      "\n",
      "तुम कितने सेल से स्तेत के लिए बहती है?\n",
      "\n",
      "-\n",
      "\tHow are you?\n",
      "\n",
      "तुम कितने सेल से स्तेत के लिए बहती है?\n",
      "\n",
      "-\n",
      "\tHow are you?\n",
      "\n",
      "तुम कितने सेल से स्तेत के लिए बहती है?\n",
      "\n",
      "-\n",
      "\tHow are you?\n",
      "\n",
      "तुम कितने सेल से स्तेत के लिए बहती है?\n",
      "\n",
      "-\n",
      "\tHow are you?\n",
      "\n",
      "तुम कितने सेल से स्तेत के लिए बहती है?\n",
      "\n",
      "-\n",
      "\tHow are you?\n",
      "\n",
      "तुम कितने सेल से स्तेत के लिए बहती है?\n",
      "\n",
      "-\n",
      "\tI am hungry.\n",
      "\n",
      "मैं अपनी काई बजास सुन किता हूँ।\n",
      "\n",
      "-\n",
      "\tI like both.\n",
      "\n",
      "मैं अपनी काई बजास सुन किता हूँ।\n",
      "\n",
      "-\n",
      "\tI like cake.\n",
      "\n",
      "मैं अपनी काई बजास सुन किता हूँ।\n",
      "\n",
      "-\n",
      "\tI like dogs.\n",
      "\n",
      "मैं अपनी काई बजास सुन किता हूँ।\n",
      "\n",
      "-\n",
      "\tI like math.\n",
      "\n",
      "मैं अपनी काई बजास सुन किता हूँ।\n",
      "\n",
      "-\n",
      "\tI'll attend.\n",
      "\n",
      "मैं अपनी काई बजास सुन किता हूँ।\n",
      "\n",
      "-\n",
      "\tNobody came.\n",
      "\n",
      "मुझे अपने आपसी बास नहीं जातते हैं।\n",
      "\n",
      "-\n",
      "\tWas I wrong?\n",
      "\n",
      "तुम कितने बजे घर जाते हो?\n",
      "\n",
      "-\n",
      "\tWhat's this?\n",
      "\n",
      "तुम कितने सेल से स्तेत के लिए आते हो क्या?\n",
      "\n",
      "-\n",
      "\tAre you sick?\n",
      "\n",
      "तुम्हे इस मौके का फ़ायदा उठाना चाहिए।\n",
      "\n",
      "-\n",
      "\tBring him in.\n",
      "\n",
      "मुझे अपने आपसी बादी नाड़ के निक्यों के पाला नहीं है।\n",
      "\n",
      "-\n",
      "\tCome with us.\n",
      "\n",
      "मुझे अपने आपसी बास नहीं जातते हैं।\n",
      "\n",
      "-\n",
      "\tHappy Easter!\n",
      "\n",
      "यह मेरी बहन की तम्मन्य है कह सुमस्ता है।\n",
      "\n",
      "-\n",
      "\tHas Tom left?\n",
      "\n",
      "यह मेरी बहन की तम्मन्य है सह सहीं।\n",
      "\n",
      "-\n",
      "\tHe is French.\n",
      "\n",
      "वह अपने कुत्ते को खादरा भर मकाने के लिए बाती है।\n",
      "\n",
      "-\n",
      "\tI am at home.\n",
      "\n",
      "मैं अपनी काई बजास सुन किता हूँ।\n",
      "\n",
      "-\n",
      "\tI can't move.\n",
      "\n",
      "मैं अपनी काई बजास सुन किता हूँ।\n",
      "\n",
      "-\n",
      "\tI don't know.\n",
      "\n",
      "मैं अपनी काई बजास सुन किता हूँ।\n",
      "\n",
      "-\n",
      "\tI don't know.\n",
      "\n",
      "मैं अपनी काई बजास सुन किता हूँ।\n",
      "\n",
      "-\n",
      "\tI have a car.\n",
      "\n",
      "मैं अपनी काई बजास सुन किता हूँ।\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for seq_index in range(100):\n",
    "    \n",
    "    input_seq = encoder_input_data[seq_index: seq_index + 1]\n",
    "    decoded_sentence = decode_sequence(input_seq)\n",
    "    print('-')\n",
    "    print(input_texts[seq_index])\n",
    "    print(decoded_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
